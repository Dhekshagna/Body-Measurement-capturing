{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Pose model\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reference object image (silhouette)\n",
    "reference_image_path = 'reference.png'\n",
    "reference_image = cv2.imread(reference_image_path, cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the reference image is loaded correctly\n",
    "if reference_image is None:\n",
    "    raise FileNotFoundError(f\"Reference image not found at {reference_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an alpha channel to the reference image if it doesn't have one\n",
    "if reference_image.shape[2] == 3:\n",
    "    b, g, r = cv2.split(reference_image)\n",
    "    alpha = np.ones(b.shape, dtype=b.dtype) * 255  # Create a white alpha channel\n",
    "    reference_image = cv2.merge((b, g, r, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the reference image translucent\n",
    "reference_image[:, :, 3] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the Euclidean distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.linalg.norm(np.array(point1) - np.array(point2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate body measurements in centimeters\n",
    "def estimate_body_measurements(landmarks, conversion_factor):\n",
    "    measurements = {}\n",
    "    \n",
    "    chest_circumference = calculate_distance(\n",
    "        (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y),\n",
    "        (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y)\n",
    "    ) * 2 * conversion_factor[1]\n",
    "    \n",
    "    waist_circumference = calculate_distance(\n",
    "        (landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y),\n",
    "        (landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y)\n",
    "    ) * 2 * conversion_factor[2]\n",
    "    \n",
    "    hip_circumference = calculate_distance(\n",
    "        (landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y),\n",
    "        (landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y)\n",
    "    ) * 2 * conversion_factor[3]\n",
    "\n",
    "    inseam_length = calculate_distance(\n",
    "        (landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y),\n",
    "        (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y)\n",
    "    ) * conversion_factor[4]\n",
    "    \n",
    "    # Calculate height from ankle to shoulder as a simple approximation\n",
    "    height = (calculate_distance(\n",
    "        (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y),\n",
    "        (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y)\n",
    "    ) + calculate_distance(\n",
    "        (landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y),\n",
    "        (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y)\n",
    "    )) / 2 * conversion_factor[7]\n",
    "\n",
    "    measurements['Height'] = height\n",
    "    measurements['Chest Circumference'] = chest_circumference\n",
    "    measurements['Waist Circumference'] = waist_circumference\n",
    "    measurements['Hip Circumference'] = hip_circumference\n",
    "    measurements['Inseam Length'] = inseam_length\n",
    "\n",
    "    return measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to overlay the reference image\n",
    "def overlay_image_alpha(img, img_overlay, pos, alpha_mask=None):\n",
    "    x, y = pos\n",
    "\n",
    "    # Image ranges\n",
    "    y1, y2 = max(0, y), min(img.shape[0], y + img_overlay.shape[0])\n",
    "    x1, x2 = max(0, x), min(img.shape[1], x + img_overlay.shape[1])\n",
    "\n",
    "    y1o, y2o = max(0, -y), min(img_overlay.shape[0], img.shape[0] - y)\n",
    "    x1o, x2o = max(0, -x), min(img_overlay.shape[1], img.shape[1] - x)\n",
    "\n",
    "    # Overlay the image\n",
    "    img_crop = img[y1:y2, x1:x2]\n",
    "    img_overlay_crop = img_overlay[y1o:y2o, x1o:x2o]\n",
    "\n",
    "    if alpha_mask is not None:\n",
    "        alpha = alpha_mask[y1o:y2o, x1o:x2o, np.newaxis] / 255.0\n",
    "        img_crop[:] = alpha * img_overlay_crop + (1.0 - alpha) * img_crop\n",
    "    else:\n",
    "        img_crop[:] = img_overlay_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_visible_from_head_to_toe(landmarks):\n",
    "    required_landmarks = [\n",
    "        mp_pose.PoseLandmark.LEFT_EYE,\n",
    "        mp_pose.PoseLandmark.RIGHT_EYE,\n",
    "        mp_pose.PoseLandmark.LEFT_FOOT_INDEX,\n",
    "        mp_pose.PoseLandmark.RIGHT_FOOT_INDEX\n",
    "    ]\n",
    "    return all(landmarks[landmark.value].visibility > 0.5 for landmark in required_landmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store all measured values as lists\n",
    "all_measurements = {\n",
    "    'Height': [],\n",
    "    'Chest Circumference': [],\n",
    "    'Waist Circumference': [],\n",
    "    'Hip Circumference': [],\n",
    "    'Inseam Length': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Ignoring empty camera frame.\")\n",
    "        continue\n",
    "\n",
    "    # Convert the image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Perform pose detection\n",
    "    results = pose.process(image_rgb)\n",
    "\n",
    "    # Resize the reference image to match the frame size\n",
    "    ref_height, ref_width, _ = image.shape\n",
    "    resized_ref_image = cv2.resize(reference_image, (ref_width, ref_height))\n",
    "\n",
    "    # Overlay the reference image on the frame\n",
    "    overlay_image_alpha(image, resized_ref_image[:, :, :3], (0, 0), resized_ref_image[:, :, 3])\n",
    "\n",
    "    # Draw the pose annotation on the image\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Extract the landmarks\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "        # Check if the person is visible from head to toe\n",
    "        if is_visible_from_head_to_toe(landmarks):\n",
    "            # Estimate body measurements (example conversion factor, adjust as needed)\n",
    "            conversion_factor = [254,283,422,520,175,180,618,210]  # Placeholder conversion factor\n",
    "            measurements = estimate_body_measurements(landmarks, conversion_factor)\n",
    "            \n",
    "            # Store the measurements in the dictionary as lists\n",
    "            for key, value in measurements.items():\n",
    "                all_measurements[key].append(value)\n",
    "            \n",
    "            # Display the measurements on the image\n",
    "            y_offset = 30\n",
    "            for key, value in measurements.items():\n",
    "                cv2.putText(image, f'{key}: {value:.2f} cm', (10, y_offset), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                y_offset += 20\n",
    "\n",
    "            \n",
    "    # Display the image\n",
    "    cv2.imshow('Pose Estimation with Reference Overlay', image)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height: 159\n",
      "Chest Circumference: 90\n",
      "Waist Circumference: 80\n",
      "Hip Circumference: 99\n",
      "Inseam Length: 79\n"
     ]
    }
   ],
   "source": [
    "for key, values in all_measurements.items():\n",
    "    print(f'{key}: {round(sum(values)/len(values))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUGGESTED SIZES: ['M', 'L', 'XL']\n"
     ]
    }
   ],
   "source": [
    "def classify_size(bust, waist, hips):\n",
    "    size_chart = {\n",
    "        'XS': {'bust': (79, 84), 'waist': (60, 65), 'hips': (84, 89)},\n",
    "        'S': {'bust': (84, 89), 'waist': (65, 70), 'hips': (89, 94)},\n",
    "        'M': {'bust': (89, 94), 'waist': (70, 75), 'hips': (94, 99)},\n",
    "        'L': {'bust': (94, 99), 'waist': (75, 80), 'hips': (99, 104)},\n",
    "        'XL': {'bust': (99, 104), 'waist': (80, 85), 'hips': (104, 109)},\n",
    "        'XXL': {'bust': (104, 109), 'waist': (85, 90), 'hips': (109, 114)},\n",
    "        'XXXL': {'bust': (109, 114), 'waist': (90, 95), 'hips': (114, 119)},\n",
    "    }\n",
    "\n",
    "    possible_sizes = []\n",
    "\n",
    "    for size, measurements in size_chart.items():\n",
    "        if measurements['bust'][0] <= bust <= measurements['bust'][1] or \\\n",
    "           measurements['waist'][0] <= waist <= measurements['waist'][1] or \\\n",
    "           measurements['hips'][0] <= hips <= measurements['hips'][1]:\n",
    "            possible_sizes.append(size)\n",
    "\n",
    "    if possible_sizes:\n",
    "        return possible_sizes\n",
    "    else:\n",
    "        return [\"Size not found\"]\n",
    "\n",
    "# Example usage\n",
    "chest = round(sum(all_measurements['Chest Circumference'])/len(all_measurements['Chest Circumference']))\n",
    "waist = round(sum(all_measurements['Waist Circumference'])/len(all_measurements['Waist Circumference']))\n",
    "hips = round(sum(all_measurements['Hip Circumference'])/len(all_measurements['Hip Circumference']))\n",
    "\n",
    "sizes = classify_size(chest, waist, hips)\n",
    "print(f\"SUGGESTED SIZES: {sizes}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
